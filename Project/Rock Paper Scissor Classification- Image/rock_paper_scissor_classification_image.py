# -*- coding: utf-8 -*-
"""Rock Paper Scissor Classification- Image.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M0hN_BXaCDDIEUZhwqn77oiCmyRkYTup

**Klasifikasi Gambar (Gunting, Batu, Kertas)**

*   **Name : Siti Ma'rufatus Sholihah**
*   **Email: sitea.maruffa@gmail.com**
"""

import tensorflow as tf
print(tf.__version__)

"""Mendownload dataset rockpapersiccors"""

!wget --no-check-certificate \
  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

"""Mengaktifkan Google drive"""

from google.colab import drive
drive.mount('/content/drive')

"""Mengekstrak dataset dengan metode unzip"""

import os
import zipfile
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

!ls "/tmp/rockpaperscissors/rps-cv-images"

"""Set directory untuk data gambar scissors, rock, dan paper"""

base_dir = '/tmp/rockpaperscissors/rps-cv-images'
scissors_dir = os.path.join(base_dir, 'scissors')
rock_dir = os.path.join(base_dir, 'rock')
paper_dir = os.path.join(base_dir, 'paper')

"""Melihat isi dataset"""

scissors_fnames = os.listdir(scissors_dir)
print("scissors:",scissors_fnames[:5])

rock_fnames = os.listdir(rock_dir)
print("rock:",rock_fnames[:5])

paper_fnames = os.listdir(paper_dir)
print("paper:",paper_fnames[:5])

print('total scissors images:', len(os.listdir(scissors_dir)))
print('total rock images:', len(os.listdir(rock_dir)))
print('total paper images:', len(os.listdir(paper_dir)))

"""Menampilkan gambar scissors, rock, paper dalam satu tampilan"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# parameter untuk grafik; menampilkan gambar dalam konfigurasi 3x4
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

nrows = 3
ncols = 4

# index awal untuk iterasi gambar
pic_index = 0

# mengatur output gambar matplotlib, dan ukurannya agar fit 4x3 gambar
fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 3)

pic_index += 4
next_scissors_pix = [os.path.join(scissors_dir, fname) 
                for fname in scissors_fnames[pic_index-4:pic_index]]
next_rock_pix = [os.path.join(rock_dir, fname) 
                for fname in rock_fnames[pic_index-4:pic_index]]
next_paper_pix = [os.path.join(paper_dir, fname) 
                for fname in paper_fnames[pic_index-4:pic_index]]

for i, img_path in enumerate(next_scissors_pix+next_rock_pix+next_paper_pix):

  # mengatur subplot; index subplot dimulai dari 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # tidak menampilkan gridlines

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

"""Menggunakan Image Data Generator

Import library yang digunakan
"""

from tensorflow import keras
from keras_preprocessing.image import ImageDataGenerator

"""Melakukan proses augmentasi gambar pada setiap sampel di dataset dan membagi data menjadi train set dan validation set dengan ukuran validation set 40% dari total dataset"""

base_dir = "/tmp/rockpaperscissors/rps-cv-images"
#proses augmentasi gambar pada sampel data training
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    width_shift_range=0.2,
                    height_shift_range=0.2,
                    rotation_range=40,
                    horizontal_flip=True,
                    zoom_range=0.2,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split=0.4              #60% Data Training dan 40% Data Validasi
                    )

"""Pelabelan data menggunakan Image Data Generator untuk mempersiapkan data latih yang akan dipelajari oleh model"""

#Generator data training
train_generator = train_datagen.flow_from_directory(
        base_dir,  # direktori data latih
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        class_mode='categorical',
        shuffle=True,
        subset='training'
        )

validation_generator = train_datagen.flow_from_directory(
        base_dir, # direktori data validasi
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        class_mode='categorical',
        shuffle=True,
        subset='validation')

"""Setting akurasi CNN

Model yang digunakan adalah model Sequential
"""

from tensorflow.keras import Sequential, layers

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

"""Melakukan compile model"""

model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
              optimizer='rmsprop', 
              metrics=['accuracy'])

"""Training model menggunakan model fit"""

history=model.fit(
    train_generator,
    steps_per_epoch=25,                   #jumlah batch yang akan dieksekusi pada setiap epoch
    epochs=25,                            #jumlah perulangan komputasi (epoch)
    validation_data=validation_generator, #menampilkan akurasi data validasi
    validation_steps=5,                   #jumlah batch yang akan dieksekusi pada setiap epoch
    verbose=2
)

"""Evaluasi akurasi dan loss dari model"""

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')

plt.ylabel('value')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.figure()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')

plt.ylabel('value')
plt.xlabel('Epoch')
plt.legend(loc="upper right")

plt.show()

"""Implementasi uji coba klasifikasi gambar rock paper scissors"""

print(train_generator.class_indices)

import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():

  # memprediksi gambar
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

  print(fn)
  if classes [0][0]==1:
    print('paper')
  elif classes [0][1]==1:
    print('rock')
  elif classes [0][2]==1:
    print('scissors')
  else:
    print('unknown')

"""Menguji perilaku model dengan Keras Callbacks"""

save_callback = keras.callbacks.ModelCheckpoint(
    "checkpoint/", save_weights_only=True, monitor="train_acc", save_best_only=False,
)

lr_scheduler = keras.callbacks.ReduceLROnPlateau(
    monitor="loss", factor=0.1, patience=3, mode="max", verbose=1
)

class MyCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs.get("accuracy") > 0.9:
            print("Accuracy over 90%, quitting training")
            self.model.stop_training = True

model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), 
              optimizer='rmsprop',
              metrics=['accuracy'])

history=model.fit(
    train_generator,
    steps_per_epoch=25,                         #jumlah batch yang akan dieksekusi pada setiap epoch
    epochs=25,                                  #jumlah perulangan komputasi (epoch)
    validation_data=validation_generator,       #menampilkan akurasi data validasi
    validation_steps=5,                         #jumlah batch yang akan dieksekusi pada setiap epoch
    verbose=2,
    callbacks=[save_callback, lr_scheduler, MyCallback()]
)